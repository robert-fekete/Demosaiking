{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    print(\"Importing data, please wait...\")\n",
    "    import os\n",
    "    import cv2\n",
    "    \n",
    "    root = r\"/home/feketrob/Demosaiking/generated_training_data/\"\n",
    "    \n",
    "    train_images = []\n",
    "    train_truth = []\n",
    "    test_images = []\n",
    "    test_truth = []\n",
    "    \n",
    "    train_set = 0\n",
    "    test_set = 0\n",
    "    train_to_test = 0.8\n",
    "    \n",
    "    for folder in sorted(os.listdir(root)):\n",
    "        \n",
    "        #folder = \"_t\"\n",
    "        path = os.path.join(root, folder)\n",
    "        images = sorted(os.listdir(path))\n",
    "        current_index = 0\n",
    "        \n",
    "        while current_index < len(images):\n",
    "            image_paths = images[current_index: current_index + 3]\n",
    "            image_b = cv2.imread(os.path.join(path, image_paths[0]), 0)\n",
    "            image_g = cv2.imread(os.path.join(path, image_paths[1]), 0)\n",
    "            image_r = cv2.imread(os.path.join(path, image_paths[2]), 0)\n",
    "            image = np.zeros((image_b.shape[0], image_b.shape[1], 3))\n",
    "            image = np.array([image_r, image_g, image_b])\n",
    "            \n",
    "            truth_paths = images[current_index + 3: current_index + 6]\n",
    "            truth_b = cv2.imread(os.path.join(path, truth_paths[0]), 0)\n",
    "            truth_g = cv2.imread(os.path.join(path, truth_paths[1]), 0)\n",
    "            truth_r = cv2.imread(os.path.join(path, truth_paths[2]), 0)\n",
    "            truth = np.zeros((truth_b.shape[0], truth_b.shape[1], 3))\n",
    "            truth = np.array([truth_r, truth_g, truth_b])\n",
    "            #truth = np.array([truth_b, truth_g, truth_r])\n",
    "            \n",
    "            if train_set > train_to_test * (train_set + test_set):\n",
    "                test_images.append(image)\n",
    "                test_truth.append(truth)\n",
    "                test_set += 1\n",
    "            else:\n",
    "                train_images.append(image)\n",
    "                train_truth.append(truth)\n",
    "                train_set += 1\n",
    "            \n",
    "            current_index += 6\n",
    "       \n",
    "    print(\"Import finished. You can stop waiting now.\")\n",
    "    return ((np.asarray(train_images), np.asarray(train_truth)), (np.asarray(test_images), np.asarray(test_truth)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data, please wait...\n",
      "Import finished. You can stop waiting now.\n",
      "[[[  0 160   0 ...   0  65   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0 149   0 ...   0  70   0]\n",
      "  ...\n",
      "  [  0 149   0 ...   0 102   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0 162   0 ...   0 102   0]]\n",
      "\n",
      " [[160   0 152 ...  32   0  44]\n",
      "  [  0 157   0 ...   0  31   0]\n",
      "  [138   0 160 ...  40   0  28]\n",
      "  ...\n",
      "  [156   0 146 ...  41   0  42]\n",
      "  [  0 165   0 ...   0  42   0]\n",
      "  [167   0 163 ...  41   0  42]]\n",
      "\n",
      " [[  0   0   0 ...   0   0   0]\n",
      "  [117   0 138 ...  24   0  19]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [129   0 114 ...  21   0  21]\n",
      "  [  0   0   0 ...   0   0   0]]]\n",
      "[[[114  70 173 ...  98  99 100]\n",
      "  [130  91 172 ...  98 102 100]\n",
      "  [127  96 165 ...  97  99 100]\n",
      "  ...\n",
      "  [152 162 157 ... 100 102 103]\n",
      "  [155 162 160 ... 102 103 103]\n",
      "  [148 162 157 ... 103 103 102]]\n",
      "\n",
      " [[117  74 178 ...  42  40  41]\n",
      "  [133  94 176 ...  42  43  41]\n",
      "  [131 100 170 ...  41  40  42]\n",
      "  ...\n",
      "  [154 169 170 ...  41  40  42]\n",
      "  [157 169 173 ...  40  42  42]\n",
      "  [152 169 170 ...  42  42  41]]\n",
      "\n",
      " [[ 98  50 149 ...  26  24  23]\n",
      "  [114  71 150 ...  26  25  23]\n",
      "  [109  76 143 ...  22  22  21]\n",
      "  ...\n",
      "  [128 142 140 ...  23  23  22]\n",
      "  [131 142 143 ...  23  25  22]\n",
      "  [125 142 140 ...  25  25  21]]]\n",
      "[[[  0 103   0 ...   0 157   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0  97   0 ...   0 169   0]\n",
      "  ...\n",
      "  [  0 107   0 ...   0 166   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0 105   0 ...   0 166   0]]\n",
      "\n",
      " [[ 49   0  49 ... 182   0 167]\n",
      "  [  0  46   0 ...   0 169   0]\n",
      "  [ 42   0  41 ... 179   0 176]\n",
      "  ...\n",
      "  [ 41   0  42 ... 182   0 177]\n",
      "  [  0  42   0 ...   0 184   0]\n",
      "  [ 41   0  42 ... 185   0 179]]\n",
      "\n",
      " [[  0   0   0 ...   0   0   0]\n",
      "  [ 30   0  29 ... 161   0 140]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [ 24   0  24 ... 160   0 153]\n",
      "  [  0   0   0 ...   0   0   0]]]\n",
      "[[[122 119 114 ...  89 102 145]\n",
      "  [108 117 109 ...  86 118 152]\n",
      "  [112 119 111 ...  83 118 156]\n",
      "  ...\n",
      "  [104 114 115 ... 101  81 106]\n",
      "  [104 112 122 ... 101  85 100]\n",
      "  [104 113 123 ... 103  87  96]]\n",
      "\n",
      " [[ 57  54  52 ...  40  64 131]\n",
      "  [ 43  53  45 ...  38  83 141]\n",
      "  [ 47  52  46 ...  35  80 142]\n",
      "  ...\n",
      "  [ 39  46  50 ...  45  30  82]\n",
      "  [ 39  47  56 ...  45  34  73]\n",
      "  [ 40  45  56 ...  46  35  71]]\n",
      "\n",
      " [[ 41  40  36 ...  21  44 108]\n",
      "  [ 27  37  29 ...  19  59 116]\n",
      "  [ 31  37  30 ...  16  60 119]\n",
      "  ...\n",
      "  [ 23  31  34 ...  26  12  58]\n",
      "  [ 23  31  43 ...  28  16  49]\n",
      "  [ 21  30  41 ...  30  17  47]]]\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "\n",
    "((train_images, train_truth), (test_images, test_truth)) = load_data()\n",
    "print(train_images[0])\n",
    "print(train_truth[0])\n",
    "print(test_images[0])\n",
    "print(test_truth[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (33601, 3, 33, 33) (33601, 3, 21, 21)\n",
      "Testing data shape :  (8400, 3, 33, 33) (8400, 3, 21, 21)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', train_images.shape, train_truth.shape)\n",
    "\n",
    "print('Testing data shape : ', test_images.shape, test_truth.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33601, 33, 33, 3)\n",
      "(33601, 21, 21, 3)\n",
      "[0.       0.627451 0.      ]\n",
      "[0.627451 0.       0.      ]\n",
      "[0.         0.59607846 0.        ]\n",
      "[0.         0.         0.45882353]\n",
      "[0.        0.6156863 0.       ]\n",
      "[0.        0.        0.5411765]\n",
      "[0.        0.5411765 0.       ]\n",
      "[0.58431375 0.         0.        ]\n",
      "[0.       0.627451 0.      ]\n",
      "----\n",
      "[0.44705883 0.45882353 0.38431373]\n",
      "[0.27450982 0.2901961  0.19607843]\n",
      "[0.6784314  0.69803923 0.58431375]\n",
      "[0.50980395 0.52156866 0.44705883]\n",
      "[0.35686275 0.36862746 0.2784314 ]\n",
      "[0.6745098 0.6901961 0.5882353]\n",
      "[0.49803922 0.5137255  0.42745098]\n",
      "[0.3764706  0.39215687 0.29803923]\n",
      "[0.64705884 0.6666667  0.56078434]\n",
      "----\n",
      "[0.         0.19215687 0.        ]\n",
      "[0.40392157 0.         0.        ]\n",
      "[0.         0.19215687 0.        ]\n",
      "[0.         0.         0.11764706]\n",
      "[0.         0.18039216 0.        ]\n",
      "[0.         0.         0.11372549]\n",
      "[0.         0.16470589 0.        ]\n",
      "[0.38039216 0.         0.        ]\n",
      "[0.         0.16078432 0.        ]\n",
      "----\n",
      "[0.47843137 0.22352941 0.16078432]\n",
      "[0.46666667 0.21176471 0.15686275]\n",
      "[0.44705883 0.20392157 0.14117648]\n",
      "[0.42352942 0.16862746 0.10588235]\n",
      "[0.45882353 0.20784314 0.14509805]\n",
      "[0.42745098 0.1764706  0.11372549]\n",
      "[0.4392157  0.18431373 0.12156863]\n",
      "[0.46666667 0.20392157 0.14509805]\n",
      "[0.43529412 0.18039216 0.11764706]\n",
      "----\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff31759fe10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the shape of input images and create the variable input_shape\n",
    "nDims, nRows,nCols = train_images.shape[1:]\n",
    "input_shape = (nRows, nCols, nDims)\n",
    "train_data = train_images\n",
    "test_data = test_images\n",
    "train_data = np.array([image.swapaxes(0, 2).swapaxes(0, 1) for image in train_images])\n",
    "test_data = np.array([image.swapaxes(0, 2).swapaxes(0, 1) for image in test_images])\n",
    "\n",
    "print(train_data.shape)\n",
    "\n",
    "nDims, nRows,nCols = train_truth.shape[1:]\n",
    "train_truth_data = train_truth\n",
    "test_truth_data = test_truth\n",
    "train_truth_data = np.array([image.swapaxes(0, 2).swapaxes(0, 1) for image in train_truth])\n",
    "test_truth_data = np.array([image.swapaxes(0, 2).swapaxes(0, 1) for image in test_truth])\n",
    "print(train_truth_data.shape)\n",
    "\n",
    "plt.figure(figsize=[4,2])\n",
    "\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_data[0], cmap='gray')\n",
    "plt.title(\"Input\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(train_truth_data[0], cmap='gray')\n",
    "plt.title(\"Result\")\n",
    "\n",
    "\n",
    "# Change to float datatype\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "train_truth_data = train_truth_data.astype('float32')\n",
    "test_truth_data = test_truth_data.astype('float32')\n",
    "\n",
    "\n",
    "#print(train_truth_data[0])\n",
    "# Scale the data to lie between 0 to 1\n",
    "train_data /= 255\n",
    "test_data /= 255\n",
    "train_truth_data /= 255\n",
    "test_truth_data /=255\n",
    "\n",
    "def print_data(data):\n",
    "    \n",
    "    for line in data[0][:3]:\n",
    "        for pixel in line[:3]:\n",
    "            print(pixel)\n",
    "    print(\"----\")\n",
    "    \n",
    "print_data(train_data)\n",
    "print_data(train_truth_data)\n",
    "print_data(test_data)\n",
    "print_data(test_truth_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gkern(kernlen=9, nsig=3):\n",
    "    \"\"\"Returns a 2D Gaussian kernel array.\"\"\"\n",
    "\n",
    "    import scipy.stats as st\n",
    "    \n",
    "    interval = (2*nsig+1.)/(kernlen)\n",
    "    x = np.linspace(-nsig-interval/2., nsig+interval/2., kernlen+1)\n",
    "    kern1d = np.diff(st.norm.cdf(x))\n",
    "    kernel_raw = np.sqrt(np.outer(kern1d, kern1d))\n",
    "    kernel = kernel_raw/kernel_raw.sum()\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def my_init(shape, dtype=None):\n",
    "    \n",
    "    print(shape)\n",
    "    return gkern(shape[0])\n",
    "\n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(128, (9, 9), activation='relu', input_shape=input_shape, kernel_initializer='random_normal'\n",
    "                    ))\n",
    "    \n",
    "    model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    "    model.add(Conv2D(3, (5, 5), kernel_initializer='random_normal'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    json_file = open(r'/home/feketrob/Demosaiking/models/long/model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(r\"/home/feketrob/Demosaiking/models/long/model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 25, 25, 128)       31232     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 25, 25, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 21, 21, 3)         4803      \n",
      "=================================================================\n",
      "Total params: 44,291\n",
      "Trainable params: 44,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33601 samples, validate on 8400 samples\n",
      "Epoch 1/50\n",
      "33601/33601 [==============================] - 7s 215us/step - loss: 0.0146 - acc: 0.6504 - val_loss: 0.0033 - val_acc: 0.7822\n",
      "Epoch 2/50\n",
      "33601/33601 [==============================] - 7s 207us/step - loss: 0.0062 - acc: 0.7236 - val_loss: 0.0037 - val_acc: 0.8321\n",
      "Epoch 3/50\n",
      "33601/33601 [==============================] - 7s 206us/step - loss: 0.0049 - acc: 0.7465 - val_loss: 0.0024 - val_acc: 0.7895\n",
      "Epoch 4/50\n",
      "33601/33601 [==============================] - 7s 208us/step - loss: 0.0040 - acc: 0.7465 - val_loss: 0.0023 - val_acc: 0.7767\n",
      "Epoch 5/50\n",
      "33601/33601 [==============================] - 7s 208us/step - loss: 0.0034 - acc: 0.7628 - val_loss: 0.0036 - val_acc: 0.7507\n",
      "Epoch 6/50\n",
      "33601/33601 [==============================] - 7s 206us/step - loss: 0.0031 - acc: 0.7789 - val_loss: 0.0019 - val_acc: 0.7663\n",
      "Epoch 7/50\n",
      "33601/33601 [==============================] - 7s 213us/step - loss: 0.0028 - acc: 0.7845 - val_loss: 0.0046 - val_acc: 0.7481\n",
      "Epoch 8/50\n",
      "33601/33601 [==============================] - 7s 206us/step - loss: 0.0025 - acc: 0.7929 - val_loss: 0.0029 - val_acc: 0.7619\n",
      "Epoch 9/50\n",
      "33601/33601 [==============================] - 7s 211us/step - loss: 0.0024 - acc: 0.7953 - val_loss: 0.0015 - val_acc: 0.8670\n",
      "Epoch 10/50\n",
      "33601/33601 [==============================] - 7s 209us/step - loss: 0.0022 - acc: 0.8019 - val_loss: 0.0029 - val_acc: 0.6610\n",
      "Epoch 11/50\n",
      "33601/33601 [==============================] - 7s 207us/step - loss: 0.0020 - acc: 0.8045 - val_loss: 0.0026 - val_acc: 0.7967\n",
      "Epoch 12/50\n",
      "33601/33601 [==============================] - 7s 206us/step - loss: 0.0019 - acc: 0.8042 - val_loss: 0.0047 - val_acc: 0.8574\n",
      "Epoch 13/50\n",
      "33601/33601 [==============================] - 7s 209us/step - loss: 0.0017 - acc: 0.8068 - val_loss: 9.4002e-04 - val_acc: 0.8311\n",
      "Epoch 14/50\n",
      "33601/33601 [==============================] - 7s 207us/step - loss: 0.0017 - acc: 0.8130 - val_loss: 0.0013 - val_acc: 0.8434\n",
      "Epoch 15/50\n",
      "33601/33601 [==============================] - 7s 208us/step - loss: 0.0016 - acc: 0.8168 - val_loss: 0.0015 - val_acc: 0.8218\n",
      "Epoch 16/50\n",
      "25344/33601 [=====================>........] - ETA: 1s - loss: 0.0015 - acc: 0.8187"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "if train:\n",
    "    model = createModel()\n",
    "    batch_size = 256\n",
    "    epochs = 50\n",
    "    model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(train_data, train_truth_data, batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "                       validation_data=(test_data, test_truth_data))\n",
    "    \n",
    "else:\n",
    "    from keras.models import model_from_json\n",
    "    mode = load_model()\n",
    "    model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "model.evaluate(test_data, test_truth_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the loss and accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    plt.figure(figsize=[8,6])\n",
    "    plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "    plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "    plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "    plt.xlabel('Epochs ',fontsize=16)\n",
    "    plt.ylabel('Loss',fontsize=16)\n",
    "    plt.title('Loss Curves',fontsize=16)\n",
    "\n",
    "    plt.figure(figsize=[8,6])\n",
    "    plt.plot(history.history['acc'],'r',linewidth=3.0)\n",
    "    plt.plot(history.history['val_acc'],'b',linewidth=3.0)\n",
    "    plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "    plt.xlabel('Epochs ',fontsize=16)\n",
    "    plt.ylabel('Accuracy',fontsize=16)\n",
    "    plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    # Save model\n",
    "    import os\n",
    "    import uuid\n",
    "\n",
    "    models_rep = r\"/home/feketrob/Demosaiking/models\"\n",
    "    folder_name = str(uuid.uuid1())\n",
    "    target_folder = os.path.join(models_rep, folder_name)\n",
    "    os.mkdir(target_folder)\n",
    "\n",
    "    model_json = model.to_json()\n",
    "    with open(os.path.join(target_folder, \"model.json\"), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(os.path.join(target_folder, \"model.h5\"))\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "    print(target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(100):\n",
    "    inputf = test_data[index]\n",
    "    #print(inputf)\n",
    "\n",
    "    result = model.predict(np.array([inputf]))[0]\n",
    "    result = np.clip(result, 0, 1)\n",
    "    plt.figure(figsize=[4,2])\n",
    "\n",
    "\n",
    "    # Display the first image in training data\n",
    "    plt.subplot(121)\n",
    "    #plt.imshow(inputf, cmap='gray')\n",
    "    #plt.title(\"Input\")\n",
    "    plt.imshow(test_truth_data[index], cmap='gray')\n",
    "    plt.title(\"Ground truth\")\n",
    "\n",
    "    # Display the first image in testing data\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(result, cmap='gray')\n",
    "    plt.title(\"Result\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
